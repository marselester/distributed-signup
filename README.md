# Distributed Signup

[![Documentation](https://godoc.org/github.com/marselester/distributed-signup?status.svg)](https://godoc.org/github.com/marselester/distributed-signup)
[![Go Report Card](https://goreportcard.com/badge/github.com/marselester/distributed-signup)](https://goreportcard.com/report/github.com/marselester/distributed-signup)

This project demonstrates a partitioned signup flow based on a primer from
"Designing Data-Intensive Applications" book by Martin Kleppmann [@martinkl](https://twitter.com/martinkl) (Thank you!): users sign up at Account service which requires a username. There are so many people willing to register,
that a single PostgreSQL database can't hold all account records, but three servers are enough for this hypothetical service load.
Therefore we should split (partition) user accounts on three databases and make sure
a username is unique across all of them.

The idea is to write signup requests into `account.signup_request` Kafka topic which is partitioned by username.
Hence all attempts to claim username Bob will be stored in the same Kafka partition based on
[consistent hashing algorithm](http://medium.com/@dgryski/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8).
For example, `{username: Bob, request_id: ca5eef915d384f28bc9b15fb754b22cf}` message is written to
`hash('Bob') % partitions_count` partition.
Since we have three PostgreSQL instances, we need to split `account.signup_request` topic into three partitions (0, 1, 2).

Each signup-server process sequentially reads Kafka messages from its own partition and
stores user accounts in its PostgreSQL database.
If Bob username exists in Postgres, the program emits a failure message to `account.signup_response` topic.
Otherwise, Bob's account is created and success message is written to the topic. For example:

- `{username: Bob, success: false, request_id: ca5eef915d384f28bc9b15fb754b22cf}`
- `{username: Bob, success: true, request_id: ca5eef915d384f28bc9b15fb754b22cf}`

Note, `request_id` is generated by a client who sends signup requests.
Request IDs are needed to deduplicate messages. IDs are kept for a certain duration
(until a message ages out) or limited by storage size. I have not tried deduplication in this project,
although I was curious what storage will be the way to go.
For instance, Segment shared how they leverage [RocksDB](http://rocksdb.org/) in [Delivering Billions of Messages Exactly Once](https://segment.com/blog/exactly-once-delivery/),
while CockroachDB uses RocksDB as a [Storage Layer](https://www.cockroachlabs.com/docs/stable/architecture/storage-layer.html#rocksdb).
Now I know what to try next!

A word about artificial keys in PostgreSQL.
UUID v4 is a common choice to generate a random unique ID for an entity, e.g., invoice ID.
Indexing of highly randomized values cause write amplification, so INSERTs become slow.
In [SQL Keys in Depth](https://begriffs.com/posts/2018-01-01-sql-keys-in-depth.html) the author
shows the superior performance of UUID v1 algorithm which produces
[node MAC address + timestamp](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_1_(date-time_and_MAC_address))
monotonically increasing values.
In this demo I used [K-Sortable Unique IDentifier](https://github.com/segmentio/ksuid) (timestamp + randomly generated payload)
to assign user IDs in PostgreSQL.
Segment goes into KSUID details in [A Brief History of the UUID](https://segment.com/blog/a-brief-history-of-the-uuid/).

## Get Started

Let's run three PostgreSQL docker containers. Note, `PGUSER` and `PGPASSWORD` will be available for `pg-ctl`, `signup-server` programs.

```sh
$ export PGUSER=account
$ export PGPASSWORD=swordfish
$ docker run --rm -it -p 5432:5432 -e POSTGRES_USER=$PGUSER -e POSTGRES_PASSWORD=$PGPASSWORD postgres:10.3-alpine
$ docker run --rm -it -p 5433:5432 -e POSTGRES_USER=$PGUSER -e POSTGRES_PASSWORD=$PGPASSWORD postgres:10.3-alpine
$ docker run --rm -it -p 5434:5432 -e POSTGRES_USER=$PGUSER -e POSTGRES_PASSWORD=$PGPASSWORD postgres:10.3-alpine
```

We also need Kafka which will have `account.signup_request` and `account.signup_response` topics
with 3 partitions and 1 replica. Set `KAFKA_ADVERTISED_HOST_NAME` to ip address from the command below
in `./docker/docker-compose.yml`.

```sh
$ cd ./docker/
$ ipconfig getifaddr en0
192.168.99.100
$ sed -i '' -- 's/my_ip_addr/192.168.99.100/g' ./docker-compose.yml
$ docker-compose up
```

Install dependencies using [dep](https://github.com/golang/dep) package manager and build all commands.

```sh
$ dep ensure
$ make build
```

Create PostgreSQL schema with pg-ctl command in every db.

```sh
$ ./pg-ctl -pgport=5432
$ ./pg-ctl -pgport=5433
$ ./pg-ctl -pgport=5434
```

Run three signup-server for each `account.signup_request` partition to process signup requests.

```sh
$ ./signup-server -partition=0 -pgport=5432
$ ./signup-server -partition=1 -pgport=5433
$ ./signup-server -partition=2 -pgport=5434
```

Finally, run signup-ctl and type usernames to send signup requests to the service.

```sh
$ ./signup-ctl
bob
2:10 13mbDc8ZLeHM1sDdu2T9bhTsrVo bob ❌
alice
2:11 13mbDz0SwD7vObBi6jA0Gd6sO1R alice ✅
```

Both programs have a debug mode which shows more service details.

## Testing

To run tests you will need Postgres and test env variables set up.

```sh
$ export TEST_PGPORT=5435
$ export TEST_PGDATABASE=test_account
$ export TEST_PGUSER=test_account
$ export TEST_PGPASSWORD=swordfish
$ docker run --rm -it -p 5435:5432 -e POSTGRES_USER=$TEST_PGUSER -e POSTGRES_PASSWORD=$TEST_PGPASSWORD postgres:10.3-alpine
$ make test
```
